{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3619e79-88c7-4cb8-aece-a5a8b70dd7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias que se necesitan\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195b4973-f652-45ca-a1e9-06a2f61efb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias para graficar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4567dee8-131a-4b77-b814-7abe7347932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el dataset de cancer de mama\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc0f8dec-063b-48fe-932a-abcd8c1abd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los datos en prueba y testeo\n",
    "\n",
    "x = data.data\n",
    "y = data.target\n",
    "import numpy as np\n",
    "def split_data(x, y):\n",
    "    _split_ones = np.round(np.where(y == 1.0)[0].shape[0]*0.5, decimals=0).astype(int)\n",
    "    _split_zeros = np.round(np.where(y == 0.0)[0].shape[0]*0.5, decimals=0).astype(int)\n",
    "    training_indexes = np.concatenate([np.where(y == 1.0)[0][:_split_ones], np.where(y == 0.0)[0][:_split_zeros]], axis=0)\n",
    "    testing_indexes = np.concatenate([np.where(y == 1.0)[0][_split_ones:], np.where(y == 0.0)[0][_split_zeros:]], axis=0)\n",
    "    return x[training_indexes, :], y[training_indexes], x[testing_indexes, :], y[testing_indexes]\n",
    "\n",
    "_x_train, _y_train, _x_test, _y_test = split_data(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eb20d3c-b28d-4e26-94d0-adc00c9fbd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([284, 30])\n",
      "torch.Size([284])\n",
      "torch.Size([285, 30])\n",
      "torch.Size([285])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape) \n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba33e3c7-f3fa-406f-9c33-c85f4651481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llamamos a la clase Model que representa nuestra red neuronal artificial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dimensions, hidden_dimensions, output_labels, feature_names, input_layer=None, output_layer=None):\n",
    "        super().__init__()\n",
    "        self.hidden_dimensions = hidden_dimensions\n",
    "        self.output_labels = output_labels\n",
    "        self.feature_names = feature_names\n",
    "        self.input_layer = nn.Linear(input_dimensions, self.hidden_dimensions) if input_layer is None else input_layer\n",
    "        self.output_layer = nn.Linear(self.hidden_dimensions, np.unique(self.output_labels).shape[0]) if output_layer is None else output_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.softmax(self.output_layer(F.relu(self.input_layer(x))), dim=1)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.input_layer.weight.detach().numpy(), self.output_layer.weight.detach().numpy()\n",
    "\n",
    "    def find_significant_features(self, top_num_features=1):\n",
    "        w, _ = self.get_weights()\n",
    "        max_contribution_per_feature = np.reshape(np.max(w, axis=1), [w.shape[0]])\n",
    "        return np.argsort(max_contribution_per_feature)[-top_num_features:]\n",
    "\n",
    "ANN = Model(_x_train.shape[1], hidden_dimensions=30, output_labels=_y_train, feature_names=data['feature_names'])\n",
    "optimizer = torch.optim.Adam(ANN.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_iterations  = 1000\n",
    "x_train = Variable(torch.from_numpy(_x_train)).float()\n",
    "y_train = Variable(torch.from_numpy(_y_train)).long()\n",
    "x_test = Variable(torch.from_numpy(_x_test)).float()\n",
    "y_test = Variable(torch.from_numpy(_y_test)).long()\n",
    "\n",
    "loss_list = np.zeros(training_iterations).astype(float)\n",
    "accuracy_list = np.zeros(training_iterations).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac1e5a3d-d5d6-44c3-81de-c3f7bd6d17ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (input_layer): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (output_layer): Linear(in_features=30, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Esta es la arquitectura de la red neuronal artificial\n",
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fef41b90-011a-42a3-b0a3-5c16add60ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _iteration in range(training_iterations):\n",
    "    y_pred = ANN(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss_list[_iteration] = loss.item()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = ANN(x_test)\n",
    "        correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\n",
    "        accuracy_list[_iteration] = correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b49134-b173-4344-a70d-edd5bf0e00d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
